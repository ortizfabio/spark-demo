spark-demo {

  akka {
    stdout-loglevel = DEBUG // defaults to WARNING can be disabled with off. The stdout-loglevel is only in effect during system startup and shutdown
    log-dead-letters-during-shutdown = on
    loglevel = DEBUG
    log-dead-letters = on
    log-config-on-start = off // Log the complete configuration at INFO level when the actor system is started

    actor {
      debug {
        receive = on // log all messages sent to an actor if that actors receive method is a LoggingReceive
        autoreceive = on // log all special messages like Kill, PoisoffPill etc sent to all actors
        lifecycle = on // log all actor lifecycle events of all actors
        fsm = on // enable logging of all events, transitioffs and timers of FSM Actors that extend LoggingFSM
        event-stream = on // enable logging of subscriptions (subscribe/unsubscribe) on the ActorSystem.eventStream
      }

      # Properties for akka.kafka.ProducerSettings can be
      # defined in this section or a configuration section with
      # the same layout.
      kafka.producer {
        # Tuning parameter of how many sends that can run in parallel.
        parallelism = 100

        # How long to wait for `KafkaProducer.close`
        close-timeout = 60s

        # Fully qualified config path which holds the dispatcher configuration
        # to be used by the producer stages. Some blocking may occur.
        # When this value is empty, the dispatcher configured for the stream
        # will be used.
        use-dispatcher = "akka.kafka.default-dispatcher"

        # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
        # can be defined in this configuration section.
        kafka-clients {
        }
      }
      kafka.consumer {
        # Tuning property of scheduled polls.
        poll-interval = 50ms

        # Tuning property of the `KafkaConsumer.poll` parameter.
        # Note that non-zero value means that blocking of the thread that
        # is executing the stage will be blocked.
        poll-timeout = 50ms

        # The stage will be await outstanding offset commit requests before
        # shutting down, but if that takes longer than this timeout it will
        # stop forcefully.
        stop-timeout = 30s

        # How long to wait for `KafkaConsumer.close`
        close-timeout = 20s

        # If offset commit requests are not completed within this timeout
        # the returned Future is completed `TimeoutException`.
        commit-timeout = 15s

        # If the KafkaConsumer can't connect to the broker the poll will be
        # aborted after this timeout. The KafkaConsumerActor will throw
        # org.apache.kafka.common.errors.WakeupException which will be ignored
        # until max-wakeups limit gets exceeded.
        wakeup-timeout = 3s

        # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
        max-wakeups = 10

        # Fully qualified config path which holds the dispatcher configuration
        # to be used by the KafkaConsumerActor. Some blocking may occur.
        use-dispatcher = "akka.kafka.default-dispatcher"

        # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
        # can be defined in this configuration section.
        kafka-clients {
          # Disable auto-commit by default
          enable.auto.commit = false
        }
      }
      test {
        single-expect-default = 10s
      }
    }
  }

  kafkaConnect {
    topic = "tweeterDemo"
    kafka.host = "localhost"
    kafka.port = "9092"
    zk.host = "localhost"
    zk.port = "2181"
    group.id = "demo-kafka-spark"
  }
  #Get your credentials from https://apps.twitter.com and replace the values below
  oauth {
    consumerKey = ""
    consumerSecret = ""
    accessToken = ""
    accessTokenSecret = ""
  }

}